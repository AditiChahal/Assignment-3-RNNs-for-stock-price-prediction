import random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping


def create_sequences(data, time_steps, future_steps=1):
  """
  Create sequences of input and its respective output data to feed into our model
  Variable passed:
    data (array): The input data.
    time_steps (int): The number of time steps to include, i.e. number of past days to consider in each sequence.
    future_steps (int): The number of future days to predict.
  Returns:
    X : Array of Input Sequences
    y : Array of X's corresponding targets
  """
  X, y = [], []
  for i in range(len(data) - time_steps - future_steps + 1):
      X.append(data[i:i + time_steps])
      y.append(data[i + time_steps:i + time_steps + future_steps])
  return np.array(X), np.array(y)


def build_model(model_type, input_shape, units, dropout_rate, learning_rate, future_steps):
  """
  Build and return a neural network model based on the specified parameters.
  Variables passed:
    model_type (str): The type of neural network model to build- 'SimpleRNN', 'LSTM', or 'GRU'
    input_shape (tuple): The shape of the input data.
    units (int): The number of units in the hidden layers.
    dropout_rate (float): The dropout rate to use in the dropout layers for regularization.
    learning_rate (float): The learning rate to use in the optimizer.
    future_steps (int): The number of future days to predict.
  Returns:
    model (Sequential): The built neural network model.
  """
  model = Sequential()
  if model_type == 'SimpleRNN':
    model.add(SimpleRNN(units, input_shape=input_shape, return_sequences=True))
    model.add(SimpleRNN(units))
  elif model_type == 'LSTM':
    model.add(LSTM(units, input_shape=input_shape, return_sequences=True))
    model.add(LSTM(units))
  elif model_type == 'GRU':
    model.add(GRU(units, input_shape=input_shape, return_sequences=True))
    model.add(GRU(units))
  # Added a dropout layer for regularization
  model.add(Dropout(dropout_rate))

  # Added a dense layer to produce the final output
  model.add(Dense(4 * future_steps)) # Since we are predicting 4 values- Open, High, Low, Close for n number of days

  # Compiled model with Adam optimizer and mean squared error loss
  optimizer = Adam(learning_rate=learning_rate)
  model.compile(optimizer=optimizer, loss='mse')
  return model


def evaluate_model(model, X_test, y_test):
  """
  Evaluate the performance of a trained model on a test dataset.
  Variables passed:
    model (Sequential): The trained neural network model.
    X_test (array): The input test data.
    y_test (array): The target test data.
  Returns:
    mse (float): The mean squared error of the model on the test data.
    predictions (array): The model's predictions on the test data.
  """
  predictions = model.predict(X_test)
  mse = mean_squared_error(y_test, predictions)
  return mse, predictions

# Set random seeds for reproducibility
np.random.seed(10)
random.seed(10)

# Loaded data from given Data set at link- https://www.kaggle.com/datasets/paultimothymooney/stock-market-data/data in nasdaq > csv folder
# In order to use some other dataset with similar structure (column names), replace name of dataset with location and name of new dataset to be used
data = pd.read_csv('BEN.csv')
prices = data[['Open', 'High', 'Low', 'Close']]

# Standardize data
scaler = StandardScaler()
prices_scaled = scaler.fit_transform(prices)

# Number of past days to use for prediction
time_step = 15
# Number of future days to predict
future_steps = 1

# Create Sequences from data 
X, y = create_sequences(prices_scaled, time_step, future_steps)
y = y.reshape(y.shape[0], -1)
# Split sequenced data in train and test (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

input_shape = (time_step, 4)

# Build RNN, LSTM and GRU models
rnn_model = build_model('SimpleRNN', input_shape, units=150, dropout_rate=0.2, learning_rate=0.001, future_steps=future_steps)
lstm_model = build_model('LSTM', input_shape, units=150, dropout_rate=0.2, learning_rate=0.001, future_steps=future_steps)
gru_model = build_model('GRU', input_shape, units=150, dropout_rate=0.2, learning_rate=0.001, future_steps=future_steps)

# Early stopping callback to prevent overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Training RNN, LSTM and GRU models
rnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])
lstm_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])
gru_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])

#Evaluate RNN, LSTM and GRU models
rnn_mse, rnn_predictions = evaluate_model(rnn_model, X_test, y_test)
lstm_mse, lstm_predictions = evaluate_model(lstm_model, X_test, y_test)
gru_mse, gru_predictions = evaluate_model(gru_model, X_test, y_test)

# Print the Mean Squared Error for each model
print(f"RNN MSE: {rnn_mse}")
print(f"LSTM MSE: {lstm_mse}")
print(f"GRU MSE: {gru_mse}")
